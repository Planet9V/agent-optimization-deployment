#!/usr/bin/env python3
"""
Comprehensive Vulnerability API & NER Model Test

Tests NER model on real CVE/CWE/Exploit data from:
1. NVD CVE API (NIST National Vulnerability Database)
2. Vulncheck API (if available)

Performs schema analysis to identify missing entity types and patterns.

Created: 2025-11-07
Purpose: Test v6 NER model on vulnerability data and identify schema gaps
"""

import os
import sys
import time
import json
import requests
import spacy
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from pathlib import Path
from typing import Dict, List, Optional

class VulnerabilityAPITester:
    """Test NER model on vulnerability data from multiple APIs."""

    NVD_API_BASE = "https://services.nvd.nist.gov/rest/json/cves/2.0"
    VULNCHECK_API_BASE = "https://api.vulncheck.com/v3"  # Public endpoint

    def __init__(self, model_path: str = "ner_model"):
        """Initialize tester with NER model."""
        print("=" * 100)
        print("VULNERABILITY API & NER MODEL COMPREHENSIVE TEST")
        print("=" * 100)

        # Load NER model
        print(f"\nðŸ“¦ Loading NER model from: {model_path}")
        self.nlp = spacy.load(model_path)
        print(f"âœ… Model loaded successfully")

        # API configuration
        self.nvd_api_key = os.getenv("NVD_API_KEY")
        self.vulncheck_api_key = os.getenv("VULNCHECK_API_KEY")

        # Results storage
        self.nvd_data = []
        self.vulncheck_data = []
        self.ner_results = {
            'nvd': [],
            'vulncheck': []
        }

    def fetch_nvd_cves(self, count: int = 40) -> List[Dict]:
        """Fetch latest CVEs from NVD API."""
        print(f"\nðŸ” Fetching {count} latest CVEs from NVD API...")

        # Get CVEs from last 30 days (sorted by modification date)
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=30)

        # Format dates for NVD API
        start_str = start_date.strftime("%Y-%m-%dT%H:%M:%S.000")
        end_str = end_date.strftime("%Y-%m-%dT%H:%M:%S.000")

        params = {
            "lastModStartDate": start_str,
            "lastModEndDate": end_str,
            "resultsPerPage": count
        }

        headers = {}
        if self.nvd_api_key:
            headers["apiKey"] = self.nvd_api_key

        try:
            response = requests.get(
                self.NVD_API_BASE,
                params=params,
                headers=headers,
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                vulnerabilities = data.get("vulnerabilities", [])
                print(f"âœ… Fetched {len(vulnerabilities)} CVEs from NVD")
                return vulnerabilities[:count]
            else:
                print(f"âŒ NVD API error: {response.status_code}")
                print(f"   Response: {response.text[:200]}")
                return []

        except Exception as e:
            print(f"âŒ NVD API error: {str(e)}")
            return []

    def fetch_vulncheck_exploits(self, count: int = 40) -> List[Dict]:
        """Fetch latest exploits from Vulncheck API (if available)."""
        print(f"\nðŸ” Attempting to fetch {count} latest exploits from Vulncheck...")

        if not self.vulncheck_api_key:
            print(f"âš ï¸  VULNCHECK_API_KEY not found in environment")
            print(f"   Skipping Vulncheck data fetch")
            print(f"   To enable: export VULNCHECK_API_KEY='your_key'")
            return []

        # Try public endpoints (may not require auth)
        try:
            headers = {
                "Authorization": f"Bearer {self.vulncheck_api_key}",
                "Accept": "application/json"
            }

            # Try the indices/exploits endpoint
            response = requests.get(
                f"{self.VULNCHECK_API_BASE}/index/exploits",
                headers=headers,
                params={"limit": count},
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                exploits = data.get("data", [])
                print(f"âœ… Fetched {len(exploits)} exploits from Vulncheck")
                return exploits
            else:
                print(f"âš ï¸  Vulncheck API returned: {response.status_code}")
                print(f"   Will continue without Vulncheck data")
                return []

        except Exception as e:
            print(f"âš ï¸  Vulncheck API error: {str(e)}")
            print(f"   Will continue without Vulncheck data")
            return []

    def extract_text_from_cve(self, cve_item: Dict) -> str:
        """Extract text content from CVE JSON for NER processing."""
        try:
            cve = cve_item.get("cve", {})

            # Build comprehensive text from CVE data
            text_parts = []

            # CVE ID
            cve_id = cve.get("id", "")
            text_parts.append(f"CVE ID: {cve_id}")

            # Description
            descriptions = cve.get("descriptions", [])
            for desc in descriptions:
                if desc.get("lang") == "en":
                    text_parts.append(f"Description: {desc.get('value', '')}")

            # CVSS metrics
            metrics = cve.get("metrics", {})

            # CVSS v3.1
            cvss_v31 = metrics.get("cvssMetricV31", [])
            for metric in cvss_v31:
                cvss_data = metric.get("cvssData", {})
                vector = cvss_data.get("vectorString", "")
                score = cvss_data.get("baseScore", 0)
                severity = cvss_data.get("baseSeverity", "")
                text_parts.append(f"CVSS v3.1: {vector} Score: {score} Severity: {severity}")

            # CWE IDs
            weaknesses = cve.get("weaknesses", [])
            for weakness in weaknesses:
                for desc in weakness.get("description", []):
                    cwe_id = desc.get("value", "")
                    text_parts.append(f"Weakness: {cwe_id}")

            # References
            references = cve.get("references", [])
            for ref in references[:5]:  # Limit to first 5 references
                url = ref.get("url", "")
                tags = ", ".join(ref.get("tags", []))
                text_parts.append(f"Reference: {url} Tags: {tags}")

            # CPE configurations (affected products)
            configurations = cve.get("configurations", [])
            for config in configurations:
                nodes = config.get("nodes", [])
                for node in nodes:
                    cpe_matches = node.get("cpeMatch", [])
                    for cpe in cpe_matches[:3]:  # First 3 CPEs
                        criteria = cpe.get("criteria", "")
                        text_parts.append(f"Affected Product: {criteria}")

            return "\n".join(text_parts)

        except Exception as e:
            print(f"âš ï¸  Error extracting text from CVE: {str(e)}")
            return ""

    def extract_text_from_exploit(self, exploit_item: Dict) -> str:
        """Extract text content from Vulncheck exploit data."""
        try:
            text_parts = []

            # Extract relevant fields
            text_parts.append(f"Exploit ID: {exploit_item.get('id', 'N/A')}")
            text_parts.append(f"Date Added: {exploit_item.get('date_added', 'N/A')}")
            text_parts.append(f"CVEs: {', '.join(exploit_item.get('cve', []))}")
            text_parts.append(f"Description: {exploit_item.get('description', 'N/A')}")
            text_parts.append(f"Source: {exploit_item.get('source', 'N/A')}")

            return "\n".join(text_parts)

        except Exception as e:
            print(f"âš ï¸  Error extracting text from exploit: {str(e)}")
            return ""

    def process_with_ner(self, text: str, source: str) -> Dict:
        """Process text through NER model."""
        try:
            doc = self.nlp(text)

            # Collect entities
            entities_by_type = defaultdict(list)
            for ent in doc.ents:
                entities_by_type[ent.label_].append(ent.text)

            return {
                'source': source,
                'text_length': len(text),
                'total_entities': len(doc.ents),
                'unique_types': len(entities_by_type),
                'entities_by_type': {k: len(v) for k, v in entities_by_type.items()},
                'unique_entities': {k: len(set(v)) for k, v in entities_by_type.items()},
                'sample_entities': {k: list(dict.fromkeys(v))[:5] for k, v in entities_by_type.items()}
            }

        except Exception as e:
            print(f"âŒ NER processing error: {str(e)}")
            return {}

    def run_comprehensive_test(self):
        """Run complete test suite."""

        # Fetch NVD CVE data
        self.nvd_data = self.fetch_nvd_cves(40)

        # Fetch Vulncheck exploit data
        self.vulncheck_data = self.fetch_vulncheck_exploits(40)

        # Process NVD CVEs through NER
        if self.nvd_data:
            print(f"\nðŸ”¬ Processing {len(self.nvd_data)} CVEs through NER model...")
            for i, cve_item in enumerate(self.nvd_data, 1):
                text = self.extract_text_from_cve(cve_item)
                if text:
                    result = self.process_with_ner(text, "NVD")
                    result['cve_id'] = cve_item.get("cve", {}).get("id", f"CVE-{i}")
                    self.ner_results['nvd'].append(result)

                    if i % 10 == 0:
                        print(f"   Processed {i}/{len(self.nvd_data)} CVEs...")

            print(f"âœ… Completed NVD CVE NER processing")

        # Process Vulncheck exploits through NER
        if self.vulncheck_data:
            print(f"\nðŸ”¬ Processing {len(self.vulncheck_data)} exploits through NER model...")
            for i, exploit_item in enumerate(self.vulncheck_data, 1):
                text = self.extract_text_from_exploit(exploit_item)
                if text:
                    result = self.process_with_ner(text, "Vulncheck")
                    result['exploit_id'] = exploit_item.get("id", f"EXPLOIT-{i}")
                    self.ner_results['vulncheck'].append(result)

                    if i % 10 == 0:
                        print(f"   Processed {i}/{len(self.vulncheck_data)} exploits...")

            print(f"âœ… Completed Vulncheck exploit NER processing")

    def analyze_schema_gaps(self):
        """Analyze NER results to identify schema gaps."""
        print("\n" + "=" * 100)
        print("ðŸ“Š COMPREHENSIVE SCHEMA ANALYSIS")
        print("=" * 100)

        # Aggregate results
        all_results = self.ner_results['nvd'] + self.ner_results['vulncheck']

        if not all_results:
            print("\nâŒ No results to analyze!")
            return

        # Count entity types found
        entity_type_counts = Counter()
        entity_type_docs = Counter()
        total_docs = len(all_results)

        for result in all_results:
            for entity_type in result.get('entities_by_type', {}).keys():
                entity_type_counts[entity_type] += result['entities_by_type'][entity_type]
                entity_type_docs[entity_type] += 1

        # Calculate coverage
        print(f"\nðŸ“ˆ ENTITY TYPE COVERAGE")
        print("-" * 100)
        print(f"Total documents processed: {total_docs}")
        print(f"Entity types found: {len(entity_type_counts)}")
        print()

        # Show found entity types
        if entity_type_counts:
            print("Entity types FOUND in vulnerability data:")
            for entity_type, count in entity_type_counts.most_common():
                coverage = (entity_type_docs[entity_type] / total_docs) * 100
                print(f"  {entity_type:25s} {count:4d} instances in {entity_type_docs[entity_type]:3d}/{total_docs} docs ({coverage:.1f}%)")
        else:
            print("âš ï¸  NO entity types found in vulnerability data!")

        # Check for expected vulnerability-related entities
        print(f"\nðŸ” VULNERABILITY-SPECIFIC ENTITY ANALYSIS")
        print("-" * 100)

        expected_entities = {
            "VULNERABILITY": "CVE IDs, vulnerability names",
            "WEAKNESS": "CWE IDs, weakness types",
            "ATTACK_VECTOR": "Remote code execution, local access",
            "MITIGATION": "Patches, fixes, workarounds",
            "VENDOR": "Software vendors, product manufacturers",
            "SOFTWARE_COMPONENT": "Affected software, libraries",
            "HARDWARE_COMPONENT": "Affected hardware, devices",
            "TECHNIQUE": "Exploitation techniques",
            "TACTIC": "Attack tactics",
            "THREAT_ACTOR": "APT groups targeting vulnerabilities"
        }

        print("\nExpected entity types and their presence:")
        for entity_type, description in expected_entities.items():
            if entity_type in entity_type_counts:
                count = entity_type_counts[entity_type]
                coverage = (entity_type_docs[entity_type] / total_docs) * 100
                status = "âœ… FOUND"
                print(f"  {status} {entity_type:25s} {count:4d} instances ({coverage:.1f}% coverage)")
                print(f"         Description: {description}")
            else:
                print(f"  âŒ MISSING {entity_type:22s} - {description}")

        # Sample extractions
        print(f"\nðŸ“ SAMPLE ENTITY EXTRACTIONS")
        print("-" * 100)

        vulnerability_entities = ["VULNERABILITY", "WEAKNESS", "ATTACK_VECTOR", "MITIGATION"]
        for entity_type in vulnerability_entities:
            if entity_type in entity_type_counts:
                print(f"\n{entity_type}:")
                # Get samples from results
                samples = set()
                for result in all_results:
                    if entity_type in result.get('sample_entities', {}):
                        samples.update(result['sample_entities'][entity_type][:2])
                        if len(samples) >= 5:
                            break

                for sample in list(samples)[:5]:
                    print(f"  â€¢ {sample}")

        # Save detailed results
        output = {
            "test_metadata": {
                "test_date": datetime.now().isoformat(),
                "total_documents": total_docs,
                "nvd_cves": len(self.ner_results['nvd']),
                "vulncheck_exploits": len(self.ner_results['vulncheck'])
            },
            "entity_coverage": {
                "found_types": dict(entity_type_counts),
                "document_coverage": dict(entity_type_docs),
                "total_entities": sum(entity_type_counts.values())
            },
            "schema_gaps": {
                "expected_but_missing": [
                    entity_type for entity_type in expected_entities.keys()
                    if entity_type not in entity_type_counts
                ],
                "expected_and_found": [
                    entity_type for entity_type in expected_entities.keys()
                    if entity_type in entity_type_counts
                ]
            },
            "detailed_results": {
                "nvd": self.ner_results['nvd'],
                "vulncheck": self.ner_results['vulncheck']
            }
        }

        output_file = Path("vulnerability_api_ner_analysis.json")
        with open(output_file, 'w') as f:
            json.dump(output, f, indent=2)

        print(f"\nðŸ’¾ Detailed analysis saved to: {output_file}")

        # Final recommendations
        print(f"\nðŸ’¡ RECOMMENDATIONS")
        print("-" * 100)

        missing = output['schema_gaps']['expected_but_missing']
        if missing:
            print(f"\nâš ï¸  Schema improvements needed:")
            print(f"   Missing {len(missing)} expected entity types:")
            for entity_type in missing:
                print(f"   - {entity_type}: {expected_entities[entity_type]}")
            print(f"\n   Consider:")
            print(f"   1. Add training data specifically for CVE/CWE vulnerability descriptions")
            print(f"   2. Ensure entity patterns include CVE-YYYY-NNNNN and CWE-NNN formats")
            print(f"   3. Train on CVSS vectors and severity descriptions")
            print(f"   4. Include exploitation technique descriptions")
        else:
            print(f"âœ… All expected vulnerability entity types are being extracted!")

        # Performance assessment
        print(f"\nðŸ“Š VULNERABILITY ENTITY EXTRACTION PERFORMANCE")
        print("-" * 100)

        vuln_entity_count = sum(count for et, count in entity_type_counts.items()
                               if et in expected_entities)
        total_entity_count = sum(entity_type_counts.values())

        if total_entity_count > 0:
            vuln_percentage = (vuln_entity_count / total_entity_count) * 100
            print(f"Vulnerability-specific entities: {vuln_entity_count}/{total_entity_count} ({vuln_percentage:.1f}%)")

            if vuln_percentage < 30:
                print(f"âš ï¸  LOW coverage of vulnerability-specific entities")
                print(f"   Most extractions are from other categories")
            elif vuln_percentage < 60:
                print(f"âœ… MODERATE coverage of vulnerability-specific entities")
            else:
                print(f"ðŸ† EXCELLENT coverage of vulnerability-specific entities")

        print("\n" + "=" * 100)
        print("âœ… COMPREHENSIVE ANALYSIS COMPLETE")
        print("=" * 100)


def main():
    """Main execution function."""
    tester = VulnerabilityAPITester(model_path="ner_model")

    # Run comprehensive test
    tester.run_comprehensive_test()

    # Analyze schema gaps
    tester.analyze_schema_gaps()


if __name__ == "__main__":
    main()
