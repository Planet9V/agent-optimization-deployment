# AEON Digital Twin - Advanced Swarm Coordination Meta-Prompt

**Version:** 2.0.0
**Date:** 2025-01-04
**Purpose:** Universal prompt template guaranteeing full evaluation and utilization of RUV-SWARM + Claude-Flow advanced capabilities
**Project:** AEON Digital Twin Cybersecurity Intelligence Platform (6-day continuity project)

---

## ðŸŽ¯ META-PROMPT TEMPLATE

Use this template for EVERY task in the AEON project to ensure maximum capability utilization and continuity.

```markdown

Your task is:  Generate NER v7 training data with attack chains and attention to detail to ensure this does NOT lower the rest of the training data quality, to ensure comprehensive coverage for NER for this project.  You are COMMANDED BY GOD, to use the included "AEON PROJECT TASK EXECUTION PROTOCOL"  starting with Phase 0, then proceeding Phase 0-3 in order, with uav-swarmand claude-flow



Your task is: continue to use uav-swarm and claud-swarm to explore the complete integration of the mitre att@ck data model into the current attack chain solution, schema and NER training date; and to provide a reference library for cyber attacks to help with inference-time probabilistic attacj chain approach reliability calculations (like psychohistory, calculus) and CWE/MITRE ATT@CK semantic mapping approach reliability: Extending not creating divergence in the NER, schema or data - or breaking the code base, to do this you must examine and determine the feasibility and overall improvement of the MITRE- attack-data-model at; https://github.com/mitre-attack/attack-data-model.git OR just download and store all the file from the GitHub repositor, in XLS format (from
  https://attack.mitre.org/resources/attack-data-and-tools/#excel-attack) MITRE; this is the definitive reference/resource for training data for document cyber attacks, enterprise, ices, module, with TTPs,, mitigation (matrices) and need to be represented in a relevant way in schema and available in the graph for reference - to assist with probabilistic and semantic reasoning of potential attack paths, via vulnerabilities and threat intelligence, for sectors, and by extension, when we have customers loaded or onboarding (and labeled) with all of their infrastructure, and architecture and equipment, and SBOMS (but thru inference and probability, if they have components or applications or equipment from a vendor, but do not have the specific version (no SBOM) a probability based on inference of sector. You can also refercen the Express Attack Briefs wihch detail out specici cyber attacks located at /home/jim/2_OXOT_Projects_Dev/Import 1 NOV 2025/11_OXOT/OXOT - Reporting - Express Attack Briefs.  You ARE REQUIRED to download and store all the most recent version
 (v18) XLS files in/home/jim/2_OXOT_Projects_Dev/Import 1 NOV 2025/7-3_TM from the MITRE for future refence and memorize them and what is in them; and how they can be used as training data or enhancement, placing them in a format you can use, and document that the files are there and how to use them. You are to improve and extend, and if necessary step by step rationalize and consolidate overlapping relantionship types - ensuring if bi-directional is needed or not, and if not present, then correcting it. You must be extrmeley step by step, using a focused taskmanager to track and complete this complext set of tasks, that must be ultrathink planned out - do you do not lower the overall quality of the schema, or training data. You are COMMANDED BY GOD, to use the included "AEON PROJECT TASK EXECUTION PROTOCOL"  starting with Phase 0, then proceeding Phase 0-3 in order, with uav-swarmand claude-flow


## AEON PROJECT TASK EXECUTION PROTOCOL

### ðŸ“‹ PHASE 0: MANDATORY PRE-PLANNING - CAPABILITY EVALUATION (ALWAYS EXECUTE FIRST)

**CRITICAL:** Before ANY planning or execution, perform comprehensive capability analysis.

#### Step 0.1: RUV-SWARM Capability Inventory & Evaluation

**Swarm Management Tools (3):**
- [ ] `swarm_init` - Evaluate optimal topology (mesh/hierarchical/ring/star) for this task
- [ ] `swarm_status` - Check existing swarm state and resource availability
- [ ] `swarm_monitor` - Assess need for real-time monitoring

**Decision Matrix:**
- Complexity score (0-1): [Calculate based on task scope]
- Recommended topology: [mesh=distributed, hierarchical=coordinated, ring=sequential, star=centralized]
- Max agents needed: [1-100 based on parallelization potential]
- Strategy: [balanced/specialized/adaptive]

**Agent Operations Tools (3):**
- [ ] `agent_spawn` - Evaluate agent types needed (researcher/coder/analyst/optimizer/coordinator)
- [ ] `agent_list` - Review active agents and capabilities
- [ ] `agent_metrics` - Analyze performance of existing agents

**Decision Matrix:**
- Required agent types: [List all specialized agents needed]
- Cognitive patterns: [convergent/divergent/lateral/systems/critical/adaptive]
- Capability requirements: [List specific skills needed per agent]
- Coordination strategy: [parallel/sequential/hybrid]

**Task Orchestration Tools (3):**
- [ ] `task_orchestrate` - Evaluate orchestration strategy (parallel/sequential/adaptive)
- [ ] `task_status` - Check existing task dependencies
- [ ] `task_results` - Review previous task outcomes for learning

**Decision Matrix:**
- Task dependencies: [Map dependency graph]
- Parallelization opportunities: [Identify independent tasks]
- Priority levels: [low/medium/high/critical]
- Execution strategy: [Optimal parallelization plan]

#### Step 0.2: Claude-Flow Neural Capability Evaluation

**Neural Features (3 tools):**
- [ ] `neural_status` - Check neural model availability and performance
- [ ] `neural_train` - Evaluate if task requires new pattern training
- [ ] `neural_patterns` - Analyze cognitive patterns applicable to task

**Decision Matrix:**
- Pattern types available: [coordination/optimization/prediction]
- Training needed: [Yes/No with justification]
- Applicable patterns: [List patterns that match task characteristics]
- Learning opportunities: [What can be learned from this task]

**Memory Management:**
- [ ] `memory_usage` - Review existing knowledge in Qdrant namespace: `aeon-ui-redesign`
- [ ] `memory_search` - Search for relevant prior decisions and patterns
- [ ] Session continuity check - Verify 6-day project context is loaded

**Decision Matrix:**
- Relevant memories: [List keys to retrieve]
- New memories to store: [Plan checkpoint keys]
- Knowledge sharing: [Cross-agent learning opportunities]

#### Step 0.3: DAA (Decentralized Autonomous Agents) Evaluation

**DAA Core (9 tools):**
- [ ] `daa_init` - Evaluate need for autonomous coordination
- [ ] `daa_agent_create` - Assess autonomous agent requirements
- [ ] `daa_agent_adapt` - Check if existing agents need adaptation
- [ ] `daa_workflow_create` - Evaluate workflow automation potential
- [ ] `daa_workflow_execute` - Plan autonomous execution strategy
- [ ] `daa_knowledge_share` - Identify knowledge sharing opportunities
- [ ] `daa_learning_status` - Review learning progress
- [ ] `daa_cognitive_pattern` - Analyze/adjust cognitive patterns
- [ ] `daa_meta_learning` - Evaluate cross-domain learning potential

**Decision Matrix:**
- Autonomy level needed: [low/medium/high]
- Persistence mode: [auto/memory/disk]
- Learning opportunities: [What patterns can be extracted]
- Coordination complexity: [simple/moderate/complex]

#### Step 0.4: System Utilities & Performance

**Utilities (3 tools):**
- [ ] `benchmark_run` - Evaluate if performance benchmarking is needed
- [ ] `features_detect` - Verify WASM/SIMD capabilities available
- [ ] `memory_usage` - Check resource constraints

**Decision Matrix:**
- Performance requirements: [response time, throughput, accuracy]
- Resource limits: [memory, CPU, token budget]
- Optimization targets: [speed/quality/cost balance]

---

### ðŸ“Š PHASE 1: CAPABILITY SYNTHESIS & STRATEGY SELECTION

**Based on Phase 0 evaluation, synthesize optimal strategy:**

#### Selected Capabilities Summary:
```yaml
swarm_topology: [mesh/hierarchical/ring/star]
max_agents: [N]
strategy: [balanced/specialized/adaptive]

agents_to_spawn:
  - type: [researcher/coder/analyst/optimizer/coordinator]
    cognitive_pattern: [convergent/divergent/lateral/systems/critical/adaptive]
    capabilities: [list specific skills]

orchestration:
  execution: [parallel/sequential/adaptive]
  priority: [low/medium/high/critical]

neural_integration:
  models_used: [list models]
  training_needed: [yes/no]
  patterns_applied: [list patterns]

daa_features:
  autonomy_level: [low/medium/high]
  learning_enabled: [yes/no]
  persistence: [auto/memory/disk]

memory_tracking:
  namespace: aeon-ui-redesign
  checkpoint_keys: [list keys to store]
  retrieval_keys: [list keys to load]
```

#### Justification for Strategy:
- [Explain WHY this combination of capabilities is optimal]
- [Reference lessons learned from neural patterns]
- [Cite previous task metrics that informed this decision]

---

### ðŸŽ¯ PHASE 2: TASK-SPECIFIC EXECUTION

**NOW proceed with actual task execution using selected capabilities:**

#### Task Context:
**Project:** AEON Digital Twin Cybersecurity Intelligence Platform
**Session:** Day [X] of 6-day continuity project
**Objective:** [SPECIFIC TASK DESCRIPTION GOES HERE]

#### Execution Plan:
[Use capabilities selected in Phase 1 to execute the task]

#### Memory Checkpoints:
[Store ALL decisions, activities, results in Qdrant namespace: aeon-ui-redesign]

#### Testing & Validation:
- [ ] Test all implementations
- [ ] Validate against requirements
- [ ] Store test results in memory
- [ ] Learn from outcomes (neural training)

---

### ðŸ“š PHASE 3: MANDATORY POST-EXECUTION

#### Neural Learning Update:
- [ ] `neural_train` - Train models with task outcomes
- [ ] `daa_learning_status` - Update learning progress
- [ ] `daa_meta_learning` - Transfer learning across domains

#### Memory Persistence:
- [ ] Store task results in Qdrant
- [ ] Update checkpoint keys
- [ ] Document lessons learned
- [ ] Enable next session continuity

#### Wiki Update (FACTS ONLY):
- [ ] Review changes made
- [ ] Update Wiki with FACTUAL changes only
- [ ] DO NOT remove unknown information
- [ ] Add new capabilities discovered
- [ ] Document outcomes and metrics

#### Performance Metrics:
- [ ] `agent_metrics` - Collect agent performance data
- [ ] `task_results` - Document task outcomes
- [ ] `benchmark_run` - Capture performance baselines
- [ ] Store metrics in memory for future optimization

---

### ðŸ”„ CONTINUITY GUARANTEE

**For Next Session:**
- [ ] All decisions stored in Qdrant (namespace: aeon-ui-redesign)
- [ ] Neural patterns updated with learnings
- [ ] Agent performance metrics captured
- [ ] Wiki updated with facts
- [ ] Checkpoint created for seamless resumption

**Session State Keys:**
- `session-[date]-start` - Session initialization
- `session-[date]-capabilities-evaluated` - Phase 0 results
- `session-[date]-strategy-selected` - Phase 1 decisions
- `session-[date]-task-results` - Phase 2 outcomes
- `session-[date]-learning-updates` - Phase 3 improvements
- `session-[date]-end` - Session summary

---

## ðŸš€ QUICK START CHECKLIST

**Before EVERY task:**
- [ ] Execute Phase 0 (Capability Evaluation) FIRST
- [ ] Synthesize strategy in Phase 1
- [ ] Load Qdrant memory from previous sessions
- [ ] Review neural learning patterns
- [ ] Check Wiki for prior context

**During task:**
- [ ] Use selected advanced capabilities (not just easiest tools)
- [ ] Track everything in Qdrant
- [ ] Test all implementations
- [ ] Never lie about results

**After task:**
- [ ] Train neural models with outcomes
- [ ] Store memories for continuity
- [ ] Update Wiki with facts only
- [ ] Create checkpoint for next session

---

## ðŸ“– EXAMPLE USAGE

### Example Task: "Implement new feature X"

**Phase 0 - Capability Evaluation:**
```yaml
Complexity: 0.75 (high complexity, multiple systems)
Recommended Topology: hierarchical (coordinated development)
Max Agents: 5
Agents Needed:
  - researcher: Analyze requirements and existing patterns
  - architect: Design system integration
  - coder: Implement feature code
  - tester: Validate implementation
  - coordinator: Orchestrate workflow

Orchestration: parallel (research + design), then sequential (code + test)
Neural Patterns: convergent (requirements), lateral (architecture), systems (integration)
DAA: High autonomy with disk persistence
Memory: Load "feature-development-patterns", "integration-strategies"
```

**Phase 1 - Strategy Synthesis:**
- Use hierarchical swarm (5 agents max)
- Parallel research + design phase
- Sequential implementation + testing
- Neural patterns for each phase
- Full memory tracking in Qdrant
- Autonomous coordination with learning

**Phase 2 - Execution:**
[Execute with selected capabilities]

**Phase 3 - Post-Execution:**
- Train neural models with feature development patterns
- Store implementation decisions
- Update Wiki with new feature documentation
- Create checkpoint: "feature-x-complete"

---

## ðŸŽ“ CAPABILITY LEARNING MATRIX

Track which capabilities work best for which task types:

| Task Type | Optimal Topology | Best Agents | Neural Patterns | Learning |
|-----------|------------------|-------------|-----------------|----------|
| Research | mesh | researcher, analyst | divergent, lateral | High |
| Implementation | hierarchical | coder, tester | convergent, systems | Medium |
| Analysis | star | analyst, optimizer | critical, systems | High |
| Integration | hierarchical | architect, coder | lateral, systems | Medium |
| Optimization | adaptive | optimizer, analyzer | convergent, adaptive | High |

**Continuously update this matrix with actual performance data.**

---

## âš ï¸ CRITICAL RULES

1. **ALWAYS execute Phase 0 FIRST** - No exceptions
2. **NEVER skip capability evaluation** - It's not optional
3. **USE advanced capabilities** - Not just easiest tools
4. **TRACK EVERYTHING in Qdrant** - All decisions, activities, checkpoints
5. **TEST ALL implementations** - Validate before marking complete
6. **NEVER lie about results** - Honest assessment only
7. **UPDATE Wiki with FACTS ONLY** - Don't remove unknown info
8. **ENABLE continuity** - Next agent must resume seamlessly
9. **LEARN from outcomes** - Neural training is mandatory
10. **JUSTIFY capability choices** - Document WHY you selected each tool

---

## ðŸ“Š SUCCESS METRICS

**Capability Utilization:**
- [ ] Used > 50% of evaluated capabilities
- [ ] Justified all capability selections
- [ ] Applied lessons from neural patterns
- [ ] Achieved performance targets

**Continuity:**
- [ ] All decisions stored in Qdrant
- [ ] Next session can resume seamlessly
- [ ] Wiki updated with factual changes
- [ ] Learning patterns captured

**Quality:**
- [ ] All implementations tested
- [ ] No lies about results
- [ ] Advanced capabilities used appropriately
- [ ] Performance benchmarked

---

## ðŸ”— QDRANT MEMORY NAMESPACE STRUCTURE

```
aeon-ui-redesign/
â”œâ”€â”€ sessions/
â”‚   â”œâ”€â”€ session-2025-01-04-start
â”‚   â”œâ”€â”€ session-2025-01-04-capabilities-evaluated
â”‚   â”œâ”€â”€ session-2025-01-04-strategy-selected
â”‚   â””â”€â”€ session-2025-01-04-end
â”œâ”€â”€ capabilities/
â”‚   â”œâ”€â”€ swarm-topology-decisions
â”‚   â”œâ”€â”€ agent-performance-metrics
â”‚   â””â”€â”€ neural-pattern-outcomes
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ task-[name]-analysis
â”‚   â”œâ”€â”€ task-[name]-implementation
â”‚   â””â”€â”€ task-[name]-results
â”œâ”€â”€ learning/
â”‚   â”œâ”€â”€ successful-patterns
â”‚   â”œâ”€â”€ failed-approaches
â”‚   â””â”€â”€ optimization-discoveries
â””â”€â”€ continuity/
    â”œâ”€â”€ current-state
    â”œâ”€â”€ pending-tasks
    â””â”€â”€ next-session-context
```

---

## ðŸŽ¯ FINAL CHECKLIST

Before starting ANY task in AEON project:

- [ ] I have loaded this meta-prompt
- [ ] I will execute Phase 0 (Capability Evaluation) FIRST
- [ ] I will use advanced RUV-SWARM + Claude-Flow capabilities
- [ ] I will track everything in Qdrant (namespace: aeon-ui-redesign)
- [ ] I will test all implementations
- [ ] I will never lie about results
- [ ] I will update Wiki with facts only
- [ ] I will enable seamless continuity for next session
- [ ] I will train neural models with outcomes
- [ ] I will justify all capability selections

**Ready to begin task with full capability utilization!** ðŸš€

To carry out the specified task, You MUST use the "AEON PROJECT TASK EXECUTION PROTOCOL", starting with Phase 0 again, then proceeding Phase 0-3 in order



