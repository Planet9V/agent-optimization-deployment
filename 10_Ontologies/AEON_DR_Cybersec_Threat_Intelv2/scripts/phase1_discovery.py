#!/usr/bin/env python3
"""
Phase 1 Discovery: CVE Data Analysis for VulnCheck Integration
Analyzes current Neo4j CVE node state to inform EPSS, KEV, and Priority Framework implementation.
"""

import sys
import json
from datetime import datetime, timedelta
from collections import Counter, defaultdict
from neo4j import GraphDatabase
from typing import Dict, List, Any

# Neo4j connection
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "neo4j@openspg"
NEO4J_DATABASE = "neo4j"

class Phase1DiscoveryAgent:
    def __init__(self):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "cve_counts": {},
            "data_quality": {},
            "distributions": {},
            "existing_enrichment": {},
            "batch_optimization": {},
            "edge_cases": {},
            "recommendations": []
        }

    def close(self):
        self.driver.close()

    def run_query(self, query: str, parameters: Dict = None) -> List[Dict]:
        """Execute Cypher query and return results"""
        with self.driver.session(database=NEO4J_DATABASE) as session:
            result = session.run(query, parameters or {})
            return [record.data() for record in result]

    def analyze_cve_counts(self):
        """1. CVE Data Quality - Count CVEs and property completeness"""
        print("\nüìä Analyzing CVE counts and data quality...")

        # Total CVE count
        query_total = "MATCH (c:CVE) RETURN count(c) as total"
        total_result = self.run_query(query_total)
        total_cves = total_result[0]['total']
        self.results['cve_counts']['total'] = total_cves
        print(f"  ‚úì Total CVEs: {total_cves:,}")

        # Property completeness
        properties_query = """
        MATCH (c:CVE)
        RETURN
            count(c.epss_score) as with_epss,
            count(c.kev_flag) as with_kev,
            count(c.priority) as with_priority,
            count(c.published_date) as with_published,
            count(c.cvss_score) as with_cvss,
            count(c.cvss_v3_score) as with_cvss_v3,
            count(c.description) as with_description
        """
        props_result = self.run_query(properties_query)
        props = props_result[0]

        self.results['data_quality']['property_counts'] = props
        self.results['data_quality']['completeness_pct'] = {
            'epss_score': round(props['with_epss'] / total_cves * 100, 2),
            'kev_flag': round(props['with_kev'] / total_cves * 100, 2),
            'priority': round(props['with_priority'] / total_cves * 100, 2),
            'published_date': round(props['with_published'] / total_cves * 100, 2),
            'cvss_score': round(props['with_cvss'] / total_cves * 100, 2),
            'cvss_v3_score': round(props['with_cvss_v3'] / total_cves * 100, 2),
            'description': round(props['with_description'] / total_cves * 100, 2)
        }

        print(f"  ‚úì Property Completeness:")
        for prop, pct in self.results['data_quality']['completeness_pct'].items():
            print(f"    - {prop}: {pct}%")

    def analyze_distributions(self):
        """2. Data Distributions - CVE publication dates, CVSS scores, age"""
        print("\nüìà Analyzing data distributions...")

        # Publication date distribution (by year)
        pub_date_query = """
        MATCH (c:CVE)
        WHERE c.published_date IS NOT NULL
        WITH c, datetime(c.published_date).year as year
        RETURN year, count(c) as count
        ORDER BY year
        """
        pub_dates = self.run_query(pub_date_query)
        self.results['distributions']['by_year'] = {str(r['year']): r['count'] for r in pub_dates}
        print(f"  ‚úì Publication dates: {len(pub_dates)} years represented")

        # CVSS score distribution
        cvss_dist_query = """
        MATCH (c:CVE)
        WHERE c.cvss_score IS NOT NULL
        WITH c,
            CASE
                WHEN c.cvss_score < 4.0 THEN 'Low (0-3.9)'
                WHEN c.cvss_score < 7.0 THEN 'Medium (4.0-6.9)'
                WHEN c.cvss_score < 9.0 THEN 'High (7.0-8.9)'
                ELSE 'Critical (9.0-10.0)'
            END as severity
        RETURN severity, count(c) as count
        ORDER BY severity
        """
        cvss_dist = self.run_query(cvss_dist_query)
        self.results['distributions']['cvss_severity'] = {r['severity']: r['count'] for r in cvss_dist}
        print(f"  ‚úì CVSS distribution: {len(cvss_dist)} severity bands")

        # CVE age distribution
        age_query = """
        MATCH (c:CVE)
        WHERE c.published_date IS NOT NULL
        WITH c, duration.between(datetime(c.published_date), datetime()).days as age_days
        WITH
            CASE
                WHEN age_days < 30 THEN 'Very Recent (< 1 month)'
                WHEN age_days < 90 THEN 'Recent (1-3 months)'
                WHEN age_days < 365 THEN 'Moderate (3-12 months)'
                WHEN age_days < 1825 THEN 'Old (1-5 years)'
                ELSE 'Legacy (> 5 years)'
            END as age_category,
            count(*) as count
        RETURN age_category, count
        ORDER BY age_category
        """
        age_dist = self.run_query(age_query)
        self.results['distributions']['cve_age'] = {r['age_category']: r['count'] for r in age_dist}
        print(f"  ‚úì Age distribution: {len(age_dist)} age categories")

    def analyze_existing_enrichment(self):
        """3. Existing Enrichment State - Detect prior enrichment"""
        print("\nüîç Analyzing existing enrichment state...")

        # Check for existing EPSS scores
        epss_query = """
        MATCH (c:CVE)
        WHERE c.epss_score IS NOT NULL
        RETURN
            count(c) as count,
            min(c.epss_score) as min_score,
            max(c.epss_score) as max_score,
            avg(c.epss_score) as avg_score
        """
        epss_result = self.run_query(epss_query)
        if epss_result[0]['count'] > 0:
            self.results['existing_enrichment']['epss'] = {
                'count': epss_result[0]['count'],
                'min': float(epss_result[0]['min_score']),
                'max': float(epss_result[0]['max_score']),
                'avg': float(epss_result[0]['avg_score'])
            }
            print(f"  ‚ö†Ô∏è  Found {epss_result[0]['count']} CVEs with EPSS scores (prior enrichment detected)")
        else:
            self.results['existing_enrichment']['epss'] = {'count': 0}
            print(f"  ‚úì No existing EPSS scores found")

        # Check for existing KEV flags
        kev_query = """
        MATCH (c:CVE)
        WHERE c.kev_flag IS NOT NULL
        RETURN count(c) as count
        """
        kev_result = self.run_query(kev_query)
        if kev_result[0]['count'] > 0:
            self.results['existing_enrichment']['kev'] = {'count': kev_result[0]['count']}
            print(f"  ‚ö†Ô∏è  Found {kev_result[0]['count']} CVEs with KEV flags (prior enrichment detected)")
        else:
            self.results['existing_enrichment']['kev'] = {'count': 0}
            print(f"  ‚úì No existing KEV flags found")

        # Check for existing priority classifications
        priority_query = """
        MATCH (c:CVE)
        WHERE c.priority IS NOT NULL
        RETURN c.priority as priority, count(c) as count
        """
        priority_result = self.run_query(priority_query)
        if priority_result:
            self.results['existing_enrichment']['priority'] = {r['priority']: r['count'] for r in priority_result}
            total_priority = sum(r['count'] for r in priority_result)
            print(f"  ‚ö†Ô∏è  Found {total_priority} CVEs with priority classifications (prior enrichment detected)")
        else:
            self.results['existing_enrichment']['priority'] = {}
            print(f"  ‚úì No existing priority classifications found")

    def analyze_batch_optimization(self):
        """4. Batch Optimization - Determine optimal batch sizes"""
        print("\n‚ö° Analyzing batch optimization parameters...")

        total_cves = self.results['cve_counts']['total']

        # Test query performance with different batch sizes
        batch_sizes = [100, 500, 1000, 5000, 10000]

        # Sample CVE IDs for testing
        sample_query = "MATCH (c:CVE) RETURN c.id as cve_id LIMIT 1000"
        sample_cves = self.run_query(sample_query)

        # Estimate based on total CVEs
        recommended_batch = 1000
        if total_cves < 10000:
            recommended_batch = 500
        elif total_cves > 100000:
            recommended_batch = 5000

        self.results['batch_optimization'] = {
            'total_cves': total_cves,
            'recommended_batch_size': recommended_batch,
            'estimated_batches': (total_cves + recommended_batch - 1) // recommended_batch,
            'batch_size_options': batch_sizes,
            'considerations': [
                "Larger batches = fewer transactions but higher memory",
                "Smaller batches = more transactions but safer for large datasets",
                f"For {total_cves:,} CVEs, {recommended_batch:,} is optimal balance"
            ]
        }

        print(f"  ‚úì Recommended batch size: {recommended_batch:,}")
        print(f"  ‚úì Estimated batches: {self.results['batch_optimization']['estimated_batches']:,}")

    def analyze_edge_cases(self):
        """5. Edge Cases - Missing properties, outliers"""
        print("\nüö® Analyzing edge cases...")

        # CVEs with missing critical properties
        missing_query = """
        MATCH (c:CVE)
        WHERE c.published_date IS NULL OR c.cvss_score IS NULL
        RETURN
            count(CASE WHEN c.published_date IS NULL THEN 1 END) as missing_published,
            count(CASE WHEN c.cvss_score IS NULL THEN 1 END) as missing_cvss,
            count(CASE WHEN c.published_date IS NULL AND c.cvss_score IS NULL THEN 1 END) as missing_both
        """
        missing_result = self.run_query(missing_query)
        self.results['edge_cases']['missing_properties'] = missing_result[0]

        print(f"  ‚ö†Ô∏è  CVEs missing published_date: {missing_result[0]['missing_published']:,}")
        print(f"  ‚ö†Ô∏è  CVEs missing cvss_score: {missing_result[0]['missing_cvss']:,}")
        print(f"  ‚ö†Ô∏è  CVEs missing both: {missing_result[0]['missing_both']:,}")

        # Very old CVEs (before 2000)
        old_cves_query = """
        MATCH (c:CVE)
        WHERE c.published_date IS NOT NULL
        AND datetime(c.published_date).year < 2000
        RETURN count(c) as count
        """
        old_result = self.run_query(old_cves_query)
        self.results['edge_cases']['very_old_cves'] = old_result[0]['count']
        print(f"  ‚ÑπÔ∏è  Very old CVEs (before 2000): {old_result[0]['count']:,}")

        # Very new CVEs (last 30 days)
        new_cves_query = """
        MATCH (c:CVE)
        WHERE c.published_date IS NOT NULL
        AND datetime(c.published_date) > datetime() - duration({days: 30})
        RETURN count(c) as count
        """
        new_result = self.run_query(new_cves_query)
        self.results['edge_cases']['very_new_cves'] = new_result[0]['count']
        print(f"  ‚ÑπÔ∏è  Very new CVEs (last 30 days): {new_result[0]['count']:,}")

        # CVEs with multiple labels (if any)
        multi_label_query = """
        MATCH (c:CVE)
        WITH c, labels(c) as labels
        WHERE size(labels) > 1
        RETURN count(c) as count
        """
        multi_label_result = self.run_query(multi_label_query)
        self.results['edge_cases']['multi_label_cves'] = multi_label_result[0]['count']
        print(f"  ‚ÑπÔ∏è  Multi-label CVEs: {multi_label_result[0]['count']:,}")

    def generate_recommendations(self):
        """Generate recommendations based on analysis"""
        print("\nüí° Generating recommendations...")

        recommendations = []

        # Data quality recommendations
        completeness = self.results['data_quality']['completeness_pct']
        if completeness['published_date'] < 95:
            recommendations.append({
                'area': 'Data Quality',
                'issue': f"Only {completeness['published_date']}% of CVEs have published_date",
                'recommendation': 'Implement fallback date handling for CVEs without publication dates',
                'priority': 'HIGH'
            })

        if completeness['cvss_score'] < 90:
            recommendations.append({
                'area': 'Data Quality',
                'issue': f"Only {completeness['cvss_score']}% of CVEs have CVSS scores",
                'recommendation': 'Priority framework must handle CVEs without CVSS scores',
                'priority': 'HIGH'
            })

        # Enrichment recommendations
        if self.results['existing_enrichment']['epss']['count'] > 0:
            recommendations.append({
                'area': 'Enrichment Strategy',
                'issue': 'Prior EPSS enrichment detected',
                'recommendation': 'Implement update strategy instead of insert-only; check timestamps',
                'priority': 'CRITICAL'
            })

        # Batch optimization recommendations
        total_cves = self.results['cve_counts']['total']
        if total_cves > 100000:
            recommendations.append({
                'area': 'Performance',
                'issue': f"Large dataset ({total_cves:,} CVEs)",
                'recommendation': f"Use batch size {self.results['batch_optimization']['recommended_batch_size']:,} with progress tracking",
                'priority': 'HIGH'
            })

        # Edge case recommendations
        missing_props = self.results['edge_cases']['missing_properties']
        if missing_props['missing_both'] > 100:
            recommendations.append({
                'area': 'Edge Cases',
                'issue': f"{missing_props['missing_both']:,} CVEs missing critical properties",
                'recommendation': 'Create separate handling logic for incomplete CVE records',
                'priority': 'MEDIUM'
            })

        self.results['recommendations'] = recommendations

        print(f"  ‚úì Generated {len(recommendations)} recommendations")
        for rec in recommendations:
            print(f"    [{rec['priority']}] {rec['area']}: {rec['recommendation']}")

    def calculate_data_quality_score(self) -> float:
        """Calculate overall data quality score (0-100)"""
        completeness = self.results['data_quality']['completeness_pct']

        # Weight critical properties
        weights = {
            'published_date': 0.25,
            'cvss_score': 0.20,
            'description': 0.15,
            'cvss_v3_score': 0.15,
            'epss_score': 0.10,
            'kev_flag': 0.10,
            'priority': 0.05
        }

        score = sum(completeness.get(prop, 0) * weight for prop, weight in weights.items())
        self.results['data_quality']['overall_score'] = round(score, 2)
        return score

    def run_discovery(self):
        """Execute complete discovery workflow"""
        print("\n" + "="*60)
        print("üî¨ PHASE 1 DISCOVERY: CVE DATA ANALYSIS")
        print("="*60)

        try:
            self.analyze_cve_counts()
            self.analyze_distributions()
            self.analyze_existing_enrichment()
            self.analyze_batch_optimization()
            self.analyze_edge_cases()
            self.generate_recommendations()

            quality_score = self.calculate_data_quality_score()

            print("\n" + "="*60)
            print("‚úÖ DISCOVERY COMPLETE")
            print("="*60)
            print(f"üìä Data Quality Score: {quality_score:.2f}%")
            print(f"üéØ Ready for Implementation: {'YES' if quality_score > 70 else 'NO (Quality issues detected)'}")

            return self.results

        except Exception as e:
            print(f"\n‚ùå Discovery failed: {e}")
            raise
        finally:
            self.close()

def main():
    """Main execution"""
    agent = Phase1DiscoveryAgent()
    results = agent.run_discovery()

    # Save results to JSON for analysis
    output_file = "/home/jim/2_OXOT_Projects_Dev/10_Ontologies/AEON_DR_Cybersec_Threat_Intelv2/scripts/phase1_discovery_results.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nüíæ Results saved to: {output_file}")

    # Return summary for report generation
    return {
        'cve_count': results['cve_counts']['total'],
        'quality_score': results['data_quality']['overall_score'],
        'edge_cases_count': len(results['edge_cases']),
        'recommended_batch_size': results['batch_optimization']['recommended_batch_size'],
        'ready_for_implementation': results['data_quality']['overall_score'] > 70
    }

if __name__ == "__main__":
    summary = main()

    # Print summary for quick reference
    print("\n" + "="*60)
    print("üìã QUICK SUMMARY")
    print("="*60)
    print(f"CVE Count: {summary['cve_count']:,}")
    print(f"Data Quality: {summary['quality_score']:.2f}%")
    print(f"Edge Cases: {summary['edge_cases_count']}")
    print(f"Recommended Batch Size: {summary['recommended_batch_size']:,}")
    print(f"Ready for Implementation: {'‚úÖ YES' if summary['ready_for_implementation'] else '‚ùå NO'}")
