#!/usr/bin/env python3
"""
INDEPENDENT API VERIFICATION - Final Production Testing
Date: 2025-12-12
Purpose: Independently verify all 128 deployed APIs work correctly
Method: Actual HTTP testing with validation
"""

import requests
import json
import sys
from typing import Dict, List, Tuple
from datetime import datetime
from collections import defaultdict

# Base configuration
BASE_URL = "http://localhost:8000"
CUSTOMER_ID = "verification-test-001"
HEADERS = {
    "Content-Type": "application/json",
    "X-Customer-ID": CUSTOMER_ID,
    "X-Namespace": CUSTOMER_ID,
    "X-Access-Level": "read"
}

# Test results storage
class TestResults:
    def __init__(self):
        self.total = 0
        self.passing = 0
        self.failing = 0
        self.errors = defaultdict(list)
        self.response_times = []
        self.results_by_category = defaultdict(lambda: {"total": 0, "passing": 0, "failing": 0})

    def add_result(self, category: str, endpoint: str, status_code: int, response_time: float, error: str = None):
        self.total += 1
        self.results_by_category[category]["total"] += 1

        if 200 <= status_code < 300:
            self.passing += 1
            self.results_by_category[category]["passing"] += 1
        else:
            self.failing += 1
            self.results_by_category[category]["failing"] += 1
            if error:
                self.errors[category].append(f"{endpoint}: HTTP {status_code} - {error}")

        self.response_times.append(response_time)

    def get_summary(self) -> Dict:
        return {
            "total_apis": self.total,
            "passing": self.passing,
            "failing": self.failing,
            "success_rate": f"{(self.passing/self.total*100):.1f}%" if self.total > 0 else "0%",
            "avg_response_time": f"{sum(self.response_times)/len(self.response_times):.0f}ms" if self.response_times else "N/A",
            "max_response_time": f"{max(self.response_times):.0f}ms" if self.response_times else "N/A"
        }

def fetch_openapi_spec() -> Dict:
    """Fetch the OpenAPI specification to get all endpoints"""
    try:
        response = requests.get(f"{BASE_URL}/openapi.json", timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"‚ùå Failed to fetch OpenAPI spec: {e}")
        sys.exit(1)

def extract_endpoints(spec: Dict) -> List[Tuple[str, str, str]]:
    """Extract all GET endpoints from OpenAPI spec"""
    endpoints = []
    paths = spec.get("paths", {})

    for path, methods in paths.items():
        for method, details in methods.items():
            if method.lower() == "get":  # Focus on GET for verification
                # Extract category from path
                parts = path.split("/")
                category = parts[3] if len(parts) >= 4 else "unknown"
                endpoints.append((category, method.upper(), path))

    return sorted(endpoints)

def test_endpoint(category: str, method: str, endpoint: str, results: TestResults) -> None:
    """Test a single API endpoint"""
    url = f"{BASE_URL}{endpoint}"

    try:
        start_time = datetime.now()
        response = requests.request(method, url, headers=HEADERS, timeout=10)
        end_time = datetime.now()
        response_time = (end_time - start_time).total_seconds() * 1000

        # Check response
        error_msg = None
        if response.status_code >= 400:
            try:
                error_data = response.json()
                error_msg = error_data.get("detail", str(error_data))[:100]
            except:
                error_msg = response.text[:100]

        results.add_result(category, endpoint, response.status_code, response_time, error_msg)

        # Print individual result
        status_icon = "‚úÖ" if 200 <= response.status_code < 300 else "‚ùå"
        print(f"{status_icon} {method:6} {endpoint:60} -> HTTP {response.status_code:3} ({response_time:5.0f}ms)")

    except requests.exceptions.Timeout:
        results.add_result(category, endpoint, 0, 0, "Timeout")
        print(f"‚è±Ô∏è  {method:6} {endpoint:60} -> TIMEOUT")
    except Exception as e:
        results.add_result(category, endpoint, 0, 0, str(e)[:100])
        print(f"‚ùå {method:6} {endpoint:60} -> ERROR: {str(e)[:50]}")

def print_summary(results: TestResults) -> None:
    """Print comprehensive test summary"""
    summary = results.get_summary()

    print("\n" + "="*100)
    print("FINAL VERIFICATION SUMMARY".center(100))
    print("="*100)

    print(f"\nüìä Overall Results:")
    print(f"   Total APIs Tested:  {summary['total_apis']}")
    print(f"   ‚úÖ Passing:         {results.passing}")
    print(f"   ‚ùå Failing:         {results.failing}")
    print(f"   Success Rate:       {summary['success_rate']}")
    print(f"   Avg Response Time:  {summary['avg_response_time']}")
    print(f"   Max Response Time:  {summary['max_response_time']}")

    print(f"\nüìã Results by Category:")
    for category, stats in sorted(results.results_by_category.items()):
        success_rate = (stats["passing"]/stats["total"]*100) if stats["total"] > 0 else 0
        print(f"   {category:20} -> {stats['passing']:3}/{stats['total']:3} passing ({success_rate:5.1f}%)")

    if results.errors:
        print(f"\n‚ö†Ô∏è  Common Errors by Category:")
        for category, errors in sorted(results.errors.items()):
            print(f"\n   {category}:")
            # Show first 3 unique errors per category
            unique_errors = list(set(errors))[:3]
            for error in unique_errors:
                print(f"      - {error}")

    print("\n" + "="*100)

    # Verdict
    if results.passing == results.total:
        print("üéâ VERDICT: ALL APIS PASSING - PRODUCTION READY ‚úÖ")
    elif results.passing >= results.total * 0.9:
        print("‚úÖ VERDICT: MOSTLY PASSING - MINOR ISSUES REMAIN")
    elif results.passing >= results.total * 0.5:
        print("‚ö†Ô∏è  VERDICT: PARTIALLY WORKING - SIGNIFICANT ISSUES")
    else:
        print("‚ùå VERDICT: FAILING - MAJOR ISSUES - NOT PRODUCTION READY")

    print("="*100 + "\n")

def main():
    """Main verification execution"""
    print("="*100)
    print("INDEPENDENT API VERIFICATION TEST".center(100))
    print(f"Date: {datetime.now().isoformat()}".center(100))
    print("="*100 + "\n")

    print(f"üîç Fetching OpenAPI specification from {BASE_URL}...")
    spec = fetch_openapi_spec()

    print(f"üìã Extracting endpoints...")
    endpoints = extract_endpoints(spec)

    print(f"‚úÖ Found {len(endpoints)} GET endpoints to test\n")
    print("="*100)
    print(f"{'Status':<6} {'Method':<6} {'Endpoint':<60} {'Result':<30}")
    print("="*100)

    # Execute tests
    results = TestResults()
    for category, method, endpoint in endpoints:
        test_endpoint(category, method, endpoint, results)

    # Print summary
    print_summary(results)

    # Save results to file
    output_file = "/home/jim/2_OXOT_Projects_Dev/docs/VERIFICATION_FINAL_2025-12-12.md"
    with open(output_file, "w") as f:
        f.write(f"# FINAL VERIFICATION REPORT - 2025-12-12\n\n")
        f.write(f"**Date**: {datetime.now().isoformat()}\n")
        f.write(f"**Tester**: Independent Verification Agent\n")
        f.write(f"**Method**: Actual HTTP testing of all deployed APIs\n\n")
        f.write(f"## Summary\n\n")
        summary = results.get_summary()
        for key, value in summary.items():
            f.write(f"- **{key}**: {value}\n")
        f.write(f"\n## Category Results\n\n")
        for category, stats in sorted(results.results_by_category.items()):
            success_rate = (stats["passing"]/stats["total"]*100) if stats["total"] > 0 else 0
            f.write(f"- **{category}**: {stats['passing']}/{stats['total']} passing ({success_rate:.1f}%)\n")

        if results.errors:
            f.write(f"\n## Errors by Category\n\n")
            for category, errors in sorted(results.errors.items()):
                f.write(f"\n### {category}\n\n")
                unique_errors = list(set(errors))
                for error in unique_errors[:10]:  # Limit to 10 errors per category
                    f.write(f"- {error}\n")

    print(f"üìù Results saved to: {output_file}\n")

    # Exit with appropriate code
    sys.exit(0 if results.passing == results.total else 1)

if __name__ == "__main__":
    main()
